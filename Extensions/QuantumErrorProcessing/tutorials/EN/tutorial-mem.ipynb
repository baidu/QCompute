{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measurement Error Mitigation\n",
    "\n",
    "*Copyright (c) 2022 Institute for Quantum Computing, Baidu Inc. All Rights Reserved.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "Measurement is used to extract the operation results of quantum circuits. Due to various reasons, the measurement equipment will contain noise, resulting in the errors of subsequent calculation results based on the measurement results. Therefore, it is very important to mitigate the measurement noise. This tutorial will introduce the theory of quantum measurement noise mitigation and its application on [Baidu Quantum Platform](https://quantum.baidu.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Theory\n",
    "The results of quantum circuits need to be measured, and the measurement will cause errors due to problems such as instruments in practical operation.\n",
    "\n",
    "A classical quantum algorithm framework is: **Preparation of initial state** -> **Evolution of quantum circuit** -> **Measurement** -> **Calculation of expected value**. Many famous quantum algorithms, such as quantum variational solver [1], quantum approximate optimization algorithm [2] and quantum machine learning [3, 4], are abstracted from this algorithm framework.\n",
    "\n",
    "Experimental data [5, 6] and theoretical analysis [7] indicate, noise in a measurement device can be viewed as classical noise, that is, a noise measurement device with $n$ qubits can be modeled as an ideal measurement device with $n$ qubits to concatenate classical Markov processes, such classical Markov processes can be described by a $2^{n} \\times 2^{n}$ column random matrix $R$：\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "m = Rt,\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "'$m$' here means measurement, that is measurement value (or output). '$t$' means truth, that is truth value (or input). Both of them are  $2^n \\times 1$ column vectors. Each element represents the number (or probability) of occurrences of a quantum state. $R$ represents the transition probability matrix, or calibration matrix. The stochastic nature of $R$'s column guarantees that it maps a probability distribution to a probability distribution. $R_{ij}$ represents the probability that the true value is $j$ but the measured value is $i$.\n",
    "\n",
    "Measurement Error Mitigation (MEM) tries to correct the errors caused by measurement operation in quantum circuits by using classical statistical methods, such as least square method. Specifically, through circuits calibration, we can obtain a calibration matrix (transition probability matrix) which can help us to know what the output of each input state will be due to the measurement noise. \n",
    "\n",
    "The specific process is summarized as follows：\n",
    "\n",
    "**Step 1:** Prepare standard base quantum states $\\lvert{x}\\rangle$ , $x\\in\\left\\{0,1\\right\\}^n$ . Sometimes we use binary expressions $x\\equiv x_0\\cdots x_{n-1}$ , $x_i\\in\\left\\{0,1\\right\\}$ .\n",
    "\n",
    "**Step 2:** Enter $\\lvert{x} \\rangle$ each time, repeat the execution of noisy measuring equipment for a total of $M $times, count the number of times the output result is binary string $y$, obtaining $M_{y\\vert x}$ , $y\\in\\left\\{0,1\\right\\}^n$ . From definition,\n",
    "\n",
    " $$\n",
    " \\begin{aligned}\n",
    " M = \\sum_{y\\in\\left\\{0,1\\right\\}^n}M_{y\\vert x}\n",
    " \\end{aligned}\n",
    " .\\tag{1}\n",
    " $$\n",
    "\n",
    "**Step 3:** Use data sets $\\left\\{M_{y\\vert x}\\right\\}_{y}$ to calculate the elements in column $x$ of noise matrix $R$ . Use $R_{yx}$ represents the element in row $y$ and column $x$ of matrix $R$ ,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\forall y\\in\\left\\{0,1\\right\\}^n,\\; R_{yx} = \\frac{M_{y\\vert x}}{M}\n",
    "\\end{aligned}\n",
    ".\\tag{2}\n",
    "$$\n",
    "\n",
    "Equation (1) ensures that the $x$ column of $R$ constructed above satisfies the column stochastic property.\n",
    "\n",
    "**Step 4:** Repeat the above three steps to calculate all elements of $R$ .\n",
    "\n",
    "If the number of qubits is $n = 3$ , we can construct the following calibration matrix $R$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\begin{array}{ll} &\n",
    "\\begin{array}{ccc} \\vert 000\\rangle & \\cdots & \\vert111\\rangle \\end{array} \\leftarrow{t, {\\rm input}}\n",
    "\\\\\n",
    "R=\\begin{array}{ccc}\n",
    "\\vert 000\\rangle \\\\\n",
    "\\vdots \\\\\n",
    "\\vert 111\\rangle \\end{array}\n",
    "&\n",
    "\\left[\n",
    "\\begin{array}{ccc}\n",
    "R_{11} &\\cdots & R_{18} \\\\\n",
    "\\vdots&\\ddots&\\vdots \\\\\n",
    "R_{81} & \\cdots & R_{88}\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\end{array},\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "to describe the statistical information of measurement noise, and this step corresponds to the **calibration** process of the quantum circuit. Obviously, the greater the total number of repetitions $ M $ in **step 2**, the more accurate the description of the noise matrix $ R $, but the greater the computational overhead. When the number of qubits $ n $ increases, the quantum measurement calibration calculation is very large. We need to prepare a total of $2^n \\times M $ initial states. In addition, the above calibration method does not consider the actual situation of quantum measurement equipment, for example, there is no crosstalk between some quantum bits. When there is no crosstalk between single qubit, quantum measurement calibration can be realized efficiently (such as **tensor product calibration**).\n",
    "\n",
    "After obtaining the calibration matrix, we can **correct** the measurement noise of the calculation results of any calculation task. Specifically, there are four methods - **Matrix inversion method**, **Least square method**, **Iterative Bayesian Unfolding (IBU) method** and **Neumann series method**. These four methods are to solve one problem:\n",
    "\n",
    "**On the premise of knowing $m$ and $r$, how to solve $t$ of $m=Rt$**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measurement calibration\n",
    "#### Complete model calibration\n",
    "Now let's talk about circuit calibration more specifically.\n",
    "\n",
    "For $n$ qubits, we enumerate all states, generate a large number of corresponding circuits, perform measurements, obtain the statistical information of each input state and its corresponding output state, and finally construct a $2^n \\times 2^n$ matrix, which is the calibration matrix, or transfer probability matrix. Such method is called **Complete Model Calibration**. \n",
    "\n",
    "It is a model that does not assume that the quantum circuit has any structure. The *\"do not assume that the quantum circuit has any structure\"* here corresponds to the **tensor product calibration** mentioned later. You can remember it first and understand it later. One advantage of full measurement calibration is that we can get all the statistical information about the measurement noise, and its disadvantages are also included in its advantages: it is quite resource-consuming, and this disadvantage does not mean that we need to completely deny it, because we only need to calibrate once to get all the information.\n",
    "\n",
    "\n",
    "#### Tensor product calibration\n",
    "In addition to complete model calibration, there is another calibration method that can characterize the measurement noise, which is **Tensor Product Calibration**.\n",
    "\n",
    "**Tensor product calibration** assumes that there is no measured crosstalk between qubits, and the quantum circuit can be regarded as an $n$ qubit composite system. According to the fourth postulate of quantum mechanics, the state space of the composite physical system is the tensor product of the state space of the sub physical system. At this time, the noise matrix can be regarded as the tensor product of each single qubit noise matrix. The specific operation is to generate $n$ qubits $\\vert 0 \\cdots 0 \\rangle$ and $\\vert 1 \\cdots 1 \\rangle $ circuits, measure and count the results of output states. \n",
    "\n",
    "It should be noted here that we need to process the statistical results. Because there are $2^n$ possible state outputs for these two states (or these two types of input circuits), but what tensor product calibration needs is to construct a $2^n \\times 2^n$ calibration matrix by calculating the tensor product of the $2 \\times 2$ calibration matrix of each qubit, which means that we should first calculate the statistical results of each qubit according to the output results, that is, **calculate the edge distribution according to the joint distribution to obtain the calibration matrix of each qubit**, and then do the tensor product to obtain the $2^n \\times 2^n$ calibration matrix.\n",
    "\n",
    "The advantage of **tensor product calibration** is obvious, which greatly reduces the required computing resources. For the simultaneous measurement of $n$ qubits, we only need to prepare $2 \\times M $ initial states, but it should be noted that **tensor product calibration** is based on the premise that there is no measurement crosstalk between qubits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measurement correction\n",
    "\n",
    "#### Matrix Inversion Method\n",
    "After we get the calibration matrix, we can use it to correct the calculation results. From $m = Rt$, we can see that the simplest and most intuitive method to solve the probability distribution **t** of the true value is to multiply both sides left by $R^{- 1} $, then\n",
    "\n",
    "$$\n",
    "t = R^{-1}m.\n",
    "$$\n",
    "\n",
    "Although this method is very simple, it is also quite rough, because we can't guarantee $R ^{-1} $ exists. Secondly, if $R^{- 1} $ exists, the computational complexity is relatively high [8]. Finally, assuming that $R^{-1} $ exists and has been calculated, we cannot guarantee that $R^{- 1}$ is a transition probability distribution, that is, there may be negative values in $R^{-1}$. For example, for a \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "R=\\left[\\begin{matrix}\n",
    " 0.75 & 0.25 \\\\\n",
    " 0.25 & 0.75\n",
    "\\end{matrix}\\right],\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "we have\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "R^{-1}=\\left[\\begin{matrix}\n",
    " 1.5 & -0.5 \\\\\n",
    " -0.5 & 1.5\n",
    "\\end{matrix}\\right],\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Based on the first disadvantage mentioned above, when we actually calculate $R^{- 1}$, we calculate its pseudo inverse [9].\n",
    "\n",
    "#### Least Square Method\n",
    "\n",
    "We can also use the least square method to solve this problem, because in essence, the problem of solving the probability distribution of true values can be regarded as the following optimization problem:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "t^\\ast = \\operatorname*{argmin}_t&\\; {\\vert \\vert m - Rt\\vert\\vert}^2, \\\\\n",
    "         {\\rm s.t.}&\\; {\\vert \\vert t\\vert\\vert}_1 = {\\vert \\vert m\\vert\\vert}_1, \\quad t_i\\geq 0.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This well solves the deficiency of matrix inversion method. Because of the constraints, we can ensure that the final result is a reasonable probability distribution.\n",
    "\n",
    "#### IBU Method\n",
    "We can also regard the problem of finding the true distribution as knowing the likelihood of $t$, solving the a posteriori probability of $t$, and correcting the data according to the a posteriori probability. This is a method based on Bayesian theorem, which is IBU method.\n",
    "\n",
    "IBU method is a data processing method based on Bayesian theorem. Bayesian theorem gives the relationship between a priori probability and a posteriori probability [10],\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "P\\left(A\\vert B\\right) = \\frac{P\\left(B\\vert A\\right)P\\left(A\\right)}{P\\left(B\\right)},\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "- $P\\left(A\\vert B\\right)$ is the conditional probability of event $A$ occurring given that $B$ is true, also known as the posteriori probability of $A$ given $B$.\n",
    "- $P\\left(A\\right)$ is a priori probability of $A$, or edge probability.\n",
    "- $P\\left(B\\vert A\\right)$ is the conditional probability of event $B$ occurring given that $A$ is true, which is also called the posteriori probability of $B$ given $A$, or the likelihood of $A$ given a fixed $B$.\n",
    "- $P\\left(B\\right)$ a priori probability of $B$.\n",
    "\n",
    "We can more simply describe Bayesian theorem as:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\text{posterior probability} = \\frac{\\text{likelihood $\\times$ prior probability}}{\\text{normalized constant}},\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Specifically for our problem, the posteriori probability of $t$ is expressed as\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "P\\left(t\\vert m\\right) = \\frac{P\\left(m\\vert t\\right)P\\left(t\\right)}{P\\left(m\\right)}.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "To start, $P\\left(m\\vert t\\right)$ is given by calibration matrix $R$. $P\\left(t\\right)$ we can first give a guessed value as the initial value, and $P\\left(m\\right)$ is given by the calibration matrix $R$ and the guessed $t$. And then, through iteration, we can constantly modify $P\\left(t\\right)$ and $P\\left(m\\right)$ to obtain more accurate $P\\left(t\\vert m\\right)$.\n",
    "\n",
    "This method has not yet given how many iterations can achieve convergence in theory. According to experience, when the number of iterations reaches $10$, it can have a good convergence effect [11]. In practice, the distance between two iterations can also be used to judge whether convergence is achieved or not.\n",
    "\n",
    "#### Neumann Series Method\n",
    "The core idea of truncated Neumann series is to approximate $R^{-1}$ by series expansion.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    R^{-1} = \\sum_{k=0}^{\\infty}\\left(I-R\\right)^k = \\sum_{k=0}^{K}c_K\\left(k\\right) R^k + \\mathcal{O}\\left(\\left(I-R\\right)^{K+1}\\right),\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $c_K\\left(k\\right)=\\left(-1\\right)^k \\dbinom{K+1}{k+1}$ using binomial series expansion.\n",
    "\n",
    "So how many orders should be expanded to ensure accuracy?\n",
    "\n",
    "Define\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    K=\\frac{\\log\\epsilon}{\\log\\xi}-1,\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $\\epsilon$ is the precision we expect, $\\xi$ is **noise resistance**, the mathematical expression is\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\xi = 2\\left(1-\\min_{x\\in\\left\\{0, 1\\right\\}^n}\\langle x\\vert R\\vert x\\rangle\\right).\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "It describes the maximum probability of measurement noise to interfere with the measurement results. It can be proved that the resulting order $K$ can well ensure the accuracy [12].\n",
    "\n",
    "Now that we have $R^{-1} $, we can act on the measurement result $m$ and get the correction result $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice\n",
    "\n",
    "### Task description\n",
    "Before the specific example display, we first have an overall grasp of the position of the two processes of measurement noise calibration and correction in the application. Through this flow chart, it is not difficult for us to understand that the process on the left is explicit from constructing the circuit of the calculation task to correcting to calculating the expected value, while the process on the right corresponds to the calibration process, which is implicit. It is hidden behind the correction process and provides a calibration matrix for the correction process. And it is worth mentioning that many quantum circuits may be constructed in one computing task. We only need to calibrate once to obtain the calibration data and construct the calibration matrix, because the calibration matrix has described the impact of measurement noise on different states, instead of constructing and running the calibration circuit every time the quantum circuit is operated.\n",
    "\n",
    "![photo](figures/mem-steps.png \"Figure 1: Flow chart of MEM\")\n",
    "\n",
    "Next, we show the measurement error mitigation through a GHZ state.\n",
    "We first generate a large number of GHZ states of $2$ qubits (strictly speaking, it should be called Bell state. For convenience of description, it is unified as GHZ state in the tutorial), measure them on the $Z$-basis, obtain the statistical information of the output states, and then calculate the expectation value of observation operator\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "O = {\\vert0\\rangle\\langle0\\vert}^{\\otimes2}+{\\vert1\\rangle\\langle1\\vert}^{\\otimes2}.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Ideally, the result should be 1, but if there is noise, the expected value will not be equal to $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noisy results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import pandas\n",
    "from QCompute import *\n",
    "\n",
    "from Extensions.QuantumErrorProcessing.qcompute_qep.measurement.correction import InverseCorrector, LeastSquareCorrector, IBUCorrector, NeumannCorrector\n",
    "from Extensions.QuantumErrorProcessing.qcompute_qep.measurement.utils import plot_histograms, dict2vector\n",
    "from Extensions.QuantumErrorProcessing.qcompute_qep.utils import expval_from_counts\n",
    "from Extensions.QuantumErrorProcessing.qcompute_qep.utils.types import get_qc_name\n",
    "from Extensions.QuantumErrorProcessing.qcompute_qep.utils.circuit import execute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to obtain the token from the Quantum Leaf to use the real quantum computing machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Please log in the \"Quantum Leaf\" platform (https://quantum-hub.baidu.com/) to get Token\n",
    "Define.hubToken = \"Token\"\n",
    "\n",
    "# Set the default maximal number of measurement shots\n",
    "MAX_SHOTS = 4096"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we begin to construct the quantum circuit corresponding to the GHZ state, and obtain the statistical results of the output state through the measurement in the $Z$ direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "qp = QEnv()\n",
    "n = 2\n",
    "qp.Q.createList(n)\n",
    "H(qp.Q[0])\n",
    "for i in range(1, n):\n",
    "    CX(qp.Q[0], qp.Q[i])\n",
    "\n",
    "MeasureZ(*qp.Q.toListPair())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we construct the observation operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "proj0 = np.array([[1, 0], [0, 0]]).astype(complex)\n",
    "proj1 = np.array([[0, 0], [0, 1]]).astype(complex)\n",
    "O = functools.reduce(np.kron, [proj0] * n) + functools.reduce(np.kron, [proj1] * n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the quantum computer to be used for calculation. LocalBaiduSim2 is the ideal simulator, and CloudBaiduQPUQian is the real quantum machine providedy by IoPCAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "ideal_qc = BackendName.LocalBaiduSim2\n",
    "\n",
    "noisy_qc = BackendName.CloudBaiduQPUQian\n",
    "\n",
    "noisy_qc_name = get_qc_name(noisy_qc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain the execution result of the quantum computer (that is the statistical information of the output state), and use the statistical information to calculate the expected value of the observation operator $O$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# WARNING! We must deep copy the quantum program since `execute` will destroy the quantum program\n",
    "\n",
    "# Ideal case.\n",
    "counts_ideal = execute(qp=copy.deepcopy(qp), qc=ideal_qc, shots=MAX_SHOTS)\n",
    "val_ideal = expval_from_counts(O, counts_ideal)\n",
    "\n",
    "print(\"The ideal expectation value is: {}\".format(val_ideal))\n",
    "\n",
    "# Noisy case.\n",
    "counts_noisy = execute(qp=copy.deepcopy(qp), qc=noisy_qc, shots=MAX_SHOTS)\n",
    "val_noisy = expval_from_counts(O, counts_noisy)\n",
    "\n",
    "print(\"The noisy expectation value is: {}\".format(val_noisy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrected results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the calculation results are obtained, we can correct the noise results. As mentioned earlier, there are two steps in MEM: calibration + correction. We provide two calibration methods: **Complete model calibration** and **Tensor product calibration**, and four correction methods: **Matrix inversion method**, **Least square method**, **IBU method** and **Neumann series method**, so there are eight methods combined. It is worth mentioning that we modify the statistical results of the output state, and then use the modified statistical results to calculate the expected value. Next, the effects of these eight methods are shown one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor product calibration + Matrix inversion method:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "corr_tp_inv = InverseCorrector(qc=noisy_qc, calibrator='tp', qubits=range(n))\n",
    "\n",
    "counts_tp_inv = corr_tp_inv.correct(counts_noisy)\n",
    "\n",
    "# Compute the expectation value from corrected counts\n",
    "val_tp_inv = expval_from_counts(O, counts_tp_inv)\n",
    "\n",
    "print(\"The 'Tensor Product Calibrator + Inverse Corrector' \"\n",
    "      \"mitigated expectation value is: {}\".format(val_tp_inv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a parameter of calibrator = 'tp' in Inversecorrector(). Here, the calibration method is selected, and the generation of calibration circuit, execution of calibration circuit and generation of calibration matrix of the calibration process are implicit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor product calibration + Least square method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "corr_tp_ls = LeastSquareCorrector(qc=noisy_qc, calibrator='tp', qubits=range(n))\n",
    "\n",
    "counts_tp_ls = corr_tp_ls.correct(counts_noisy)\n",
    "\n",
    "# Compute the expectation value from corrected counts\n",
    "val_tp_ls = expval_from_counts(O, counts_tp_ls)\n",
    "\n",
    "print(\"The 'Tensor Product Calibrator + Least Square Corrector' \"\n",
    "      \"mitigated expectation value is: {}\".format(val_tp_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor product calibration + IBU method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "corr_tp_ibu = IBUCorrector(qc=noisy_qc, calibrator='tp', qubits=range(n))\n",
    "counts_tp_ibu = corr_tp_ibu.correct(counts_noisy)\n",
    "# Compute the expectation value from corrected counts\n",
    "val_tp_ibu = expval_from_counts(O, counts_tp_ibu)\n",
    "\n",
    "print(\"The 'Tensor Product Calibrator + Iterative Bayesian Unfolding Corrector' \"\n",
    "      \"mitigated expectation value is: {}\".format(val_tp_ibu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor product calibration + Neumann method："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "corr_tp_neu = NeumannCorrector(qc=noisy_qc, calibrator='tp', qubits=range(n))\n",
    "counts_tp_neu = corr_tp_neu.correct(counts_noisy)\n",
    "# Compute the expectation value from corrected counts\n",
    "val_tp_neu = expval_from_counts(O, counts_tp_neu)\n",
    "\n",
    "print(\"The 'Tensor Product Calibrator + Truncated Neumann Series Corrector' \"\n",
    "      \"mitigated expectation value is: {}\".format(val_tp_neu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete model calibration + Matrix inversion method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "corr_cp_inv = InverseCorrector(qc=noisy_qc, calibrator='complete', qubits=range(n))\n",
    "\n",
    "counts_cp_inv = corr_cp_inv.correct(counts_noisy)\n",
    "\n",
    "# Compute the expectation value from corrected counts\n",
    "val_cp_inv = expval_from_counts(O, counts_cp_inv)\n",
    "\n",
    "print(\"The 'Complete Calibrator + Inverse Corrector' \"\n",
    "      \"mitigated expectation value is: {}\".format(val_cp_inv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete model calibration + Least square method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "corr_cp_ls = LeastSquareCorrector(qc=noisy_qc, calibrator='complete', qubits=range(n))\n",
    "\n",
    "counts_cp_ls = corr_cp_ls.correct(counts_noisy)\n",
    "\n",
    "# Compute the expectation value from corrected counts\n",
    "val_cp_ls = expval_from_counts(O, counts_cp_ls)\n",
    "\n",
    "print(\"The 'Complete Calibrator + Least Square Corrector' \"\n",
    "      \"mitigated expectation value is: {}\".format(val_cp_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete model calibration + IBU method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "corr_cp_ibu = IBUCorrector(qc=noisy_qc, calibrator='complete', qubits=range(n))\n",
    "counts_cp_ibu = corr_cp_ibu.correct(counts_noisy)\n",
    "# Compute the expectation value from corrected counts\n",
    "val_cp_ibu = expval_from_counts(O, counts_cp_ibu)\n",
    "\n",
    "print(\"The 'Complete Calibrator + Iterative Bayesian Unfolding Corrector' \"\n",
    "      \"mitigated expectation value is: {}\".format(val_cp_ibu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete model calibration + Neumann method："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "corr_cp_neu = NeumannCorrector(qc=noisy_qc, calibrator='complete', qubits=range(n))\n",
    "counts_cp_neu = corr_cp_neu.correct(counts_noisy)\n",
    "# Compute the expectation value from corrected counts\n",
    "val_cp_neu = expval_from_counts(O, counts_cp_neu)\n",
    "\n",
    "print(\"The 'Complete Calibrator + Truncated Neumann Series Corrector' \"\n",
    "      \"mitigated expectation value is: {}\".format(val_cp_neu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will visualize all the results to get a more intuitive effect.\n",
    "\n",
    "Let's look at how it works to the counts. The $\\vert01\\rangle$ and $\\vert10\\rangle$ generated by the noise are mitigated effectively. We can see that the mitigation effect is quite well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the ideal, noisy, and mitigated counts\n",
    "counts_list = [dict2vector(counts_ideal),\n",
    "               dict2vector(counts_noisy),\n",
    "               dict2vector(counts_tp_inv), dict2vector(counts_tp_ls), dict2vector(counts_tp_ibu), dict2vector(counts_tp_neu),\n",
    "               dict2vector(counts_cp_inv), dict2vector(counts_cp_ls), dict2vector(counts_cp_ibu), dict2vector(counts_cp_neu)]\n",
    "legends = ['Ideal', 'Noisy', 'TP+INV', 'TP+LS', 'TP+IBU', 'TP+Neumann', 'CP+INV', 'CP+LS', 'CP+IBU', 'CP+Neumann']\n",
    "\n",
    "plot_histograms(counts_list, legends,\n",
    "                title=\"GHZ in Quantum Computer {}\".format(noisy_qc_name),\n",
    "                fig_name=\"GHZ_Counts_MEM_{}_N{}.png\".format(noisy_qc_name, n))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then for the expectation value. It can be noted that there are observable improvements for these eight cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Visualize the ideal, noisy, and mitigated expectation values\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "\n",
    "expval_list = [val_ideal, val_noisy, val_tp_inv, val_tp_ls, val_tp_ibu, val_tp_neu, val_cp_inv, val_cp_ls, val_cp_ibu, val_cp_neu]\n",
    "expval_array = np.zeros((len(expval_list), 2))\n",
    "for i, val in enumerate(expval_list):\n",
    "    expval_array[i][0] = i\n",
    "    expval_array[i][1] = val\n",
    "\n",
    "df = pandas.DataFrame(expval_array, columns=[\"Measurement Error Mitigation Method\", \"Expectation Value\"])\n",
    "seaborn.barplot(x=df['Measurement Error Mitigation Method'],\n",
    "                y=df['Expectation Value'],\n",
    "                palette=seaborn.color_palette(\"Paired\"))\n",
    "\n",
    "# Add the theoretical reference line\n",
    "plt.axhline(y=1, color='black', linestyle='-.', linewidth=1, zorder=1)\n",
    "\n",
    "ax.set_xticklabels(legends)\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "ax.set_title(\"GHZ in Quantum Computer {}\".format(noisy_qc_name), fontsize=12)\n",
    "# plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"GHZ_ExpVal_MEM_{}_N{}.png\".format(noisy_qc_name, n),\n",
    "            format='png',\n",
    "            dpi=600,\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=0.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Through a simple example of GHZ state, we can see how calibration and correction are applied to the calculation process, what roles they play, and how they cooperate with each other to correct the statistical results containing measurement noise.\n",
    "\n",
    "According to the results of different combinations of these eight calibrations and corrections, we can see that the results are very good. Theoretically, compared with tensor product calibration, the correction results based on complete model calibration are generally closer to the true value, because complete model calibration obtains all the statistical information of measurement noise at the cost of resources. In practical application, We need to make a trade-off between the two calibration methods, because we can also see that the correction results based on tensor product calibration also have quite good accuracy, which is a cost-effective model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Peruzzo, Alberto, et al. \"A variational eigenvalue solver on a photonic quantum processor.\" [Nature Communications](https://www.nature.com/articles/ncomms5213), 5.1 (2014): 1-7.\n",
    "\n",
    "[2] Farhi, Edward, Jeffrey Goldstone, and Sam Gutmann. \"A quantum approximate optimization algorithm.\" [arXiv](https://arxiv.org/abs/1411.4028) preprint arXiv:1411.4028, 2014.\n",
    "\n",
    "[3] Biamonte, Jacob, et al. \"Quantum machine learning.\" [Nature](https://www.nature.com/articles/nature23474) 549.7671 (2017): 195-202.\n",
    "\n",
    "[4] Havlíček, Vojtěch, et al. \"Supervised learning with quantum-enhanced feature spaces.\" [Nature](https://www.nature.com/articles/s41586-019-0980-2), 567.7747 (2019): 209-212.\n",
    "\n",
    "[5] Chow, Jerry M., et al. \"Universal quantum gate set approaching fault-tolerant thresholds with superconducting qubits.\" [Physical Review Letters](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.109.060501) 109.6 (2012): 060501.\n",
    "\n",
    "[6] Kandala, Abhinav, et al. \"Error mitigation extends the computational reach of a noisy quantum processor.\" [Nature](https://www.nature.com/articles/s41586-019-1040-7), 567.7749 (2019): 491-495.\n",
    "\n",
    "[7] Michael R Geller. \"Rigorous measurement error correction.\" [Quantum Science and Technology](https://iopscience.iop.org/article/10.1088/2058-9565/ab9591), 5(3):03LT01, 2020.\n",
    "\n",
    "[8] Wikipedia contributors. \"Computational complexity of mathematical operations.\" [Wikipedia](https://en.wikipedia.org/wiki/Computational_complexity_of_mathematical_operations), 2021. \n",
    "\n",
    "[9] Wikipedia contributors. \"Moore–Penrose inverse.\" [Wikipedia](https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse), 2021.\n",
    "\n",
    "[10] Wikipedia contributors. \"Bayes' theorem.\" [Wikipedia](https://en.wikipedia.org/wiki/Bayes%27_theorem), 2021.\n",
    "\n",
    "[11] Nachman, Benjamin, et al. \"Unfolding quantum computer readout noise.\" [npj Quantum Information](https://arxiv.org/abs/1910.01969) 6.1 (2020): 1-7.\n",
    "\n",
    "[12] Wang, Kun, Yu-Ao Chen, and Xin Wang. \"Measurement Error Mitigation via Truncated Neumann Series.\" [arXiv](https://arxiv.org/abs/2103.13856) preprint arXiv:2103.13856, 2021."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "原始单元格格式",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
